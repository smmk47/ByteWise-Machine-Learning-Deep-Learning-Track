{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a6dff7-72f4-4d74-8ca2-ed36e9a0f7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device: cuda (NVIDIA GeForce RTX 3050 6GB Laptop GPU)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6780561804771423\n",
      "Epoch 2, Loss: 0.6881519556045532\n",
      "Epoch 3, Loss: 0.637283205986023\n",
      "Epoch 4, Loss: 0.5908198952674866\n",
      "Epoch 5, Loss: 0.7011416554450989\n",
      "RNN Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.55      0.55      4961\n",
      "           1       0.55      0.54      0.54      5039\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.55      0.55      0.55     10000\n",
      "weighted avg       0.55      0.55      0.55     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:544: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7061896324157715\n",
      "Epoch 2, Loss: 0.6997522115707397\n",
      "Epoch 3, Loss: 0.6761562824249268\n",
      "Epoch 4, Loss: 0.6950558423995972\n",
      "Epoch 5, Loss: 0.6951999068260193\n",
      "Hybrid Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.66      4961\n",
      "           1       0.00      0.00      0.00      5039\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.25      0.50      0.33     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_7004\\2725229254.py:183: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rnn_model.load_state_dict(torch.load('rnn_model.pth'))\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_7004\\2725229254.py:187: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  hybrid_model.load_state_dict(torch.load('hybrid_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RNN Model:\n",
      "Review: This movie was fantastic! I loved every moment of it. | Sentiment: Positive\n",
      "Testing Hybrid Model:\n",
      "Review: This movie was fantastic! I loved every moment of it. | Sentiment: Negative\n",
      "Testing RNN Model:\n",
      "Review: I really didn't like this film. It was a waste of time. | Sentiment: Negative\n",
      "Testing Hybrid Model:\n",
      "Review: I really didn't like this film. It was a waste of time. | Sentiment: Negative\n",
      "Testing RNN Model:\n",
      "Review: The plot was okay, but the acting was terrible. | Sentiment: Negative\n",
      "Testing Hybrid Model:\n",
      "Review: The plot was okay, but the acting was terrible. | Sentiment: Negative\n",
      "Testing RNN Model:\n",
      "Review: An absolute masterpiece! A must-watch for everyone. | Sentiment: Positive\n",
      "Testing Hybrid Model:\n",
      "Review: An absolute masterpiece! A must-watch for everyone. | Sentiment: Negative\n",
      "Testing RNN Model:\n",
      "Review: It was boring and too long. I wouldn't recommend it. | Sentiment: Positive\n",
      "Testing Hybrid Model:\n",
      "Review: It was boring and too long. I wouldn't recommend it. | Sentiment: Negative\n",
      "Testing RNN Model:\n",
      "Review: The cinematography was beautiful, but the story fell flat. | Sentiment: Negative\n",
      "Testing Hybrid Model:\n",
      "Review: The cinematography was beautiful, but the story fell flat. | Sentiment: Negative\n",
      "Testing RNN Model:\n",
      "Review: I enjoyed it, but it could have been better. | Sentiment: Negative\n",
      "Testing Hybrid Model:\n",
      "Review: I enjoyed it, but it could have been better. | Sentiment: Negative\n",
      "Testing RNN Model:\n",
      "Review: What a terrible movie! I can't believe I wasted my money. | Sentiment: Negative\n",
      "Testing Hybrid Model:\n",
      "Review: What a terrible movie! I can't believe I wasted my money. | Sentiment: Negative\n",
      "Testing RNN Model:\n",
      "Review: A delightful experience! I would watch it again. | Sentiment: Positive\n",
      "Testing Hybrid Model:\n",
      "Review: A delightful experience! I would watch it again. | Sentiment: Negative\n",
      "Testing RNN Model:\n",
      "Review: Not my cup of tea, but I can see why others might like it. | Sentiment: Negative\n",
      "Testing Hybrid Model:\n",
      "Review: Not my cup of tea, but I can see why others might like it. | Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Check if GPU is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f'Using device: {device} ({torch.cuda.get_device_name(0)})')\n",
    "\n",
    "# Load the IMDb Movie Reviews dataset\n",
    "data = pd.read_csv('data/IMDB Dataset.csv')\n",
    "\n",
    "# Basic data cleaning function\n",
    "def clean_text(text):  \n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  \n",
    "    return text.lower()\n",
    "\n",
    "# Apply cleaning to the review column\n",
    "data['cleaned_text'] = data['review'].apply(clean_text)\n",
    "\n",
    "# Encode labels (positive: 1, negative: 0)\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['sentiment'])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_text'], data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenization for GPT-2 model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "max_length = 100\n",
    "\n",
    "def encode_data(texts, labels, tokenizer, max_length):\n",
    "    # Tokenize the texts\n",
    "    encodings = tokenizer(texts.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    # Convert labels to tensor\n",
    "    labels = torch.tensor(labels.values)\n",
    "    return TensorDataset(encodings['input_ids'], encodings['attention_mask'], labels)\n",
    "\n",
    "train_dataset = encode_data(X_train, y_train, tokenizer, max_length)\n",
    "test_dataset = encode_data(X_test, y_test, tokenizer, max_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Define the RNN model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_classes):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = len(tokenizer)\n",
    "embed_size = 64\n",
    "hidden_size = 64\n",
    "num_classes = 1\n",
    "\n",
    "# Initialize and train the RNN model\n",
    "rnn_model = RNNModel(vocab_size, embed_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop for RNN\n",
    "for epoch in range(5):\n",
    "    rnn_model.train()\n",
    "    for input_ids, attention_mask, labels in train_loader:\n",
    "        input_ids, labels = input_ids.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = rnn_model(input_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Save the RNN model\n",
    "torch.save(rnn_model.state_dict(), 'rnn_model.pth')\n",
    "\n",
    "# Evaluate the RNN model\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, labels in data_loader:\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            if isinstance(model, RNNModel):\n",
    "                outputs = model(input_ids)\n",
    "            else:\n",
    "                outputs = model(input_ids, attention_mask)  # Pass both input_ids and attention_mask\n",
    "            preds = torch.sigmoid(outputs).round()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return all_labels, all_preds\n",
    "\n",
    "y_true, y_pred_rnn = evaluate_model(rnn_model, test_loader)\n",
    "print(\"RNN Model Evaluation:\")\n",
    "print(classification_report(y_true, y_pred_rnn))\n",
    "\n",
    "# Define the Hybrid Model (GPT-2 + CNN + RNN)\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, transformer_model, hidden_size, num_classes):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        self.cnn = nn.Conv1d(in_channels=768, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.rnn = nn.RNN(64, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        transformer_output = self.transformer(input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        transformer_output = transformer_output.permute(0, 2, 1)\n",
    "        cnn_output = self.cnn(transformer_output)\n",
    "        cnn_output = cnn_output.permute(0, 2, 1)\n",
    "        h0 = torch.zeros(1, cnn_output.size(0), 64).to(device)\n",
    "        rnn_output, _ = self.rnn(cnn_output, h0)\n",
    "        out = self.fc(rnn_output[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Load pre-trained GPT-2 model\n",
    "transformer_model = GPT2Model.from_pretrained('gpt2').to(device)\n",
    "\n",
    "# Initialize and train the hybrid model\n",
    "hybrid_model = HybridModel(transformer_model, hidden_size=64, num_classes=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(hybrid_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop for Hybrid Model\n",
    "for epoch in range(5):\n",
    "    hybrid_model.train()\n",
    "    for input_ids, attention_mask, labels in train_loader:\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device).float().unsqueeze(1)\n",
    "        outputs = hybrid_model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Save the Hybrid model\n",
    "torch.save(hybrid_model.state_dict(), 'hybrid_model.pth')\n",
    "\n",
    "# Evaluate the Hybrid model\n",
    "y_true, y_pred_hybrid = evaluate_model(hybrid_model, test_loader)\n",
    "print(\"Hybrid Model Evaluation:\")\n",
    "print(classification_report(y_true, y_pred_hybrid))\n",
    "\n",
    "# Testing models with diverse reviews\n",
    "def test_model(model, tokenizer, input_text):\n",
    "    cleaned_text = clean_text(input_text)\n",
    "    encoding = tokenizer(cleaned_text, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    input_ids, attention_mask = encoding['input_ids'].to(device), encoding['attention_mask'].to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(model, RNNModel):\n",
    "            output = model(input_ids)\n",
    "        else:\n",
    "            output = model(input_ids, attention_mask)\n",
    "        prediction = torch.sigmoid(output).round().cpu().numpy()[0][0]\n",
    "    sentiment = \"Positive\" if prediction == 1 else \"Negative\"\n",
    "    return sentiment\n",
    "\n",
    "# Load the RNN model\n",
    "rnn_model = RNNModel(vocab_size, embed_size, hidden_size, num_classes).to(device)\n",
    "rnn_model.load_state_dict(torch.load('rnn_model.pth'))\n",
    "\n",
    "# Load the Hybrid model\n",
    "hybrid_model = HybridModel(transformer_model, hidden_size=64, num_classes=1).to(device)\n",
    "hybrid_model.load_state_dict(torch.load('hybrid_model.pth'))\n",
    "\n",
    "# Test the models with a variety of reviews\n",
    "reviews_to_test = [\n",
    "    \"This movie was fantastic! I loved every moment of it.\",\n",
    "    \"I really didn't like this film. It was a waste of time.\",\n",
    "    \"The plot was okay, but the acting was terrible.\",\n",
    "    \"An absolute masterpiece! A must-watch for everyone.\",\n",
    "    \"It was boring and too long. I wouldn't recommend it.\",\n",
    "    \"The cinematography was beautiful, but the story fell flat.\",\n",
    "    \"I enjoyed it, but it could have been better.\",\n",
    "    \"What a terrible movie! I can't believe I wasted my money.\",\n",
    "    \"A delightful experience! I would watch it again.\",\n",
    "    \"Not my cup of tea, but I can see why others might like it.\"\n",
    "]\n",
    "\n",
    "for review in reviews_to_test:\n",
    "    print(\"Testing RNN Model:\")\n",
    "    print(f\"Review: {review} | Sentiment: {test_model(rnn_model, tokenizer, review)}\")\n",
    "    print(\"Testing Hybrid Model:\")\n",
    "    print(f\"Review: {review} | Sentiment: {test_model(hybrid_model, tokenizer, review)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d370c3d-dde1-4e67-9288-28e0ea06030b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eb19c3-352e-4415-aece-455b0067fe17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac93565-1f23-42d0-8c73-1cb92054811b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eef8b0-8425-48d4-b327-62d9b9e6a2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30514aa4-5d38-44d2-a8ef-5bafab5ce3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a4343a-cb8b-4864-b86f-76f209cb1901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78da505-d25a-470a-974f-5357b8c092d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c93207-90ad-486a-8c56-26c77114d5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c248453-fa94-44be-9074-60306996bf54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8566d3-a786-417b-a684-0e55f798dd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2abd35e-0c99-4b3f-8a84-526051546d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4a47b-1a66-44ae-8b8b-826c00bb688e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65644b45-98b5-4eb6-b912-7ba046db0aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b644b-8723-4004-aa00-8868869d7e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bcd369-781e-4cdf-8e25-8336dc989dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe7937-9701-4244-80ac-c50dc15734cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4eef3c-bd2d-4c15-9944-921ceb1b08b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b2746-6ee1-44a6-8633-c9389513eab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a32fed-ba9b-4bad-a2c6-e40d3626207d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2bcb31-125c-4523-97e5-a08403b6f534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f2cf9-9401-4c8a-9c8f-7078489adfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6088c1da-912c-4cd6-9770-7fef80f7560b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b598d-5692-4f76-8d6d-84f946a29023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a12293e-7359-4bbb-97e1-7942ee2902f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77becb05-927b-4791-894b-41287d2e53f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50e65e3-2ca9-4dac-853e-615b65329b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
